<!doctype html><html lang="ja"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="description" content="AI関連情報の更新をまとめたRSSフィードを配信しています。記事を読んでAI技術の最新動向や質の高い技術情報を得られることを目的としています。"><meta name="author" content="univac-1"><meta name="robots" content="index, follow"><meta property="og:url" content="https://univac-1.github.io/ai-info-rss-feed/"><meta property="og:title" content="Zennの「ディープラーニング」のフィードのフィード｜AI関連情報RSS"><meta property="og:image" content="https://univac-1.github.io/ai-info-rss-feed/images/og-image.png"><meta property="og:description" content="AI関連情報の更新をまとめたRSSフィードを配信しています。記事を読んでAI技術の最新動向や質の高い技術情報を得られることを目的としています。"><meta property="og:type" content="website"><meta property="og:site_name" content="AI関連情報RSS"><meta property="og:locale" content="ja_JP"><meta name="twitter:card" content="summary"><meta property="twitter:domain" content="https://univac-1.github.io/ai-info-rss-feed/"><meta property="twitter:url" 
content="https://univac-1.github.io/ai-info-rss-feed/"><meta name="twitter:title" content="Zennの「ディープラーニング」のフィードのフィード｜AI関連情報RSS"><meta name="twitter:description" content="AI関連情報の更新をまとめたRSSフィードを配信しています。記事を読んでAI技術の最新動向や質の高い技術情報を得られることを目的としています。"><meta name="twitter:image" content="https://univac-1.github.io/ai-info-rss-feed/images/og-image.png"><meta name="thumbnail" content="https://univac-1.github.io/ai-info-rss-feed/images/og-image.png"><link rel="preload" href="../../styles/bundle.css" as="style"><meta name="google-site-verification" content="GPLvXv8kYtLMW912ZS54DKFEZL6ruOrjOFLdHVTo37o"><link rel="shortcut icon" href="../../images/favicon.ico"><link rel="apple-touch-icon" href="../../images/apple-icon.png"><link rel="alternate" type="application/atom+xml" title="Atom Feed" href="../../feeds/atom.xml"><link rel="alternate" type="application/rss+xml" title="RSS2.0" href="../../feeds/rss.xml"><link rel="alternate" type="application/json" href="../../feeds/feed.json"><link 
rel="stylesheet" type="text/css" href="../../styles/bundle.css"><script async src="https://www.googletagmanager.com/gtag/js?id=G-CNNNTL0NB3"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-CNNNTL0NB3")</script><title>Zennの「ディープラーニング」のフィードのフィード｜AI関連情報RSS</title></head><body><header role="banner" class="ui-section-header"><div class="ui-layout-container"><div class="ui-section-header__layout ui-layout-flex"><a href="https://univac-1.github.io/ai-info-rss-feed/" role="link" aria-label="#"><img src="../../images/icon.png" alt="サイトロゴ" loading="eager" width="96" height="96"> <span class="ui-section-header__title">AI関連情報RSS</span></a><div class="ui-section-header__links"><a href="https://github.com/univac-1/ai-info-rss-feed/" role="link" aria-label="#" target="_blank"><img src="../../images/icon-github.png" alt="GitHubロゴ" loading="eager" width="96" height="96"> </a><a href="https://x.com/univac-1" 
role="link" aria-label="#" target="_blank"><img src="../../images/icon-x.png" alt="Xロゴ" loading="eager" width="96" height="96"></a></div></div></div></header><main role="main"><nav class="ui-nav"><div class="ui-layout-container"><div class="ui-section-nav__layout ui-layout-flex"><a class="ui-section-nav__link" href="../../">フィード</a> <a class="ui-section-nav__link" href="../../hot/">人気フィード</a> <a class="ui-section-nav__link" href="../../blogs/">ブログ一覧</a></div></div></nav><section class="ui-section-content ui-section-feed"><div class="ui-layout-container"><h2 class="ui-typography-heading">Zennの「ディープラーニング」のフィード</h2><div class="ui-container-blog-summary"><div class="ui-blog-summary"><a class="ui-blog-summary__link" href="https://zenn.dev/topics/deeplearning">https://zenn.dev/topics/deeplearning</a><p class="ui-blog-summary__description"></p></div></div><h3 class="ui-typography-heading">フィード</h3><div 
class="ui-section-content--feature ui-layout-grid ui-layout-grid-3 ui-container-feed ui-container-feed--no-image"><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/doctorin/articles/b940e0954bd24d"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/qR5rprBnyK-256.avif 256w, ../../images/feed-thumbnails/qR5rprBnyK-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/qR5rprBnyK-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/qR5rprBnyK-256.jpeg 256w, ../../images/feed-thumbnails/qR5rprBnyK-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/doctorin/articles/b940e0954bd24d">【論文解説】HQ-VAE: 階層的な離散表現学習における確率的量子化（SQ）の導入</a><div 
class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">本記事では、以下の論文で提案された HQ-VAE の概要と主要な成果について解説します。先行研究との対応が分かりやすいよう、自作の図を交えながら数式や変数表記を整理しています。ただし文字が斜体か否かについては、本記事では区別できていません。ご了承ください。 要約本論文では、階層的な離散潜在表現を学習する新たな変分オートエンコーダ (Variational Autoencoder; VAE) フレームワークである HQ-VAE が提案されている。従来広く用いられてきた VQ-VAE 系列（VQ-VAE-2 や RQ-VAE など）は、離散コードブックを使って入力データを量子化...</div><div class="ui-feed-item__date" title="2025-03-09 22:37:36">17時間前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/intel_developer/articles/82f74c7e5b80ae"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/74RcZBemJm-256.avif 256w, ../../images/feed-thumbnails/74RcZBemJm-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/74RcZBemJm-256.jpeg" width="512" height="268" 
srcset="../../images/feed-thumbnails/74RcZBemJm-256.jpeg 256w, ../../images/feed-thumbnails/74RcZBemJm-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/intel_developer/articles/82f74c7e5b80ae">Llama2 のファインチューニングに低ランク適応 (LoRA) を使用</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">https://www.intel.com/content/www/us/en/developer/articles/training/fine-tuning-llama2-model-with-lora.htmlインテル® Gaudi® 2 AI アクセラレーターに実装する Llama2 ファインチューニングの低ランク適応 (LoRA) による効率化https://github.com/HabanaAI/Gaudi-tutorials/blob/main/PyTorch/llama2_fine_tuning_inference/llama2_fine_tuning_inferenc...</div><div class="ui-feed-item__date" title="2025-03-09 02:39:00">2日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/kakky_hacker/articles/652bd7f9a1e6c1">
<picture><source type="image/avif" srcset="../../images/feed-thumbnails/Waw6T4e9dF-256.avif 256w, ../../images/feed-thumbnails/Waw6T4e9dF-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/Waw6T4e9dF-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/Waw6T4e9dF-256.jpeg 256w, ../../images/feed-thumbnails/Waw6T4e9dF-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/kakky_hacker/articles/652bd7f9a1e6c1">[深層強化学習] RustでDQN (Deep Q Network) をフルスクラッチで実装してみた</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">
※ 2025/03/01にqiitaに投稿した記事を同じ内容でzennに投稿してます。 はじめに個人開発しているRust製の強化学習フレームワーク（ReinforceX）にDQNを実装したので、それについて解説する記事です。gitレポジトリはこちらになります（もしこの記事が良かったらStarを付けてもらえると、やる気がでます！）。また、crates.ioにもreinforcexという名のクレートとして公開しています。 本記事でやること実装したDQNでCartPoleを学習してみるAPIについての解説DQNの実装についての解説（下記の実装も含む）ε-greedy法...</div><div class="ui-feed-item__date" title="2025-03-05 09:41:00">5日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/boh_mouse/articles/1e84d170b4212a"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/VPPZ_meBC2-256.avif 256w, ../../images/feed-thumbnails/VPPZ_meBC2-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/VPPZ_meBC2-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/VPPZ_meBC2-256.jpeg 256w, ../../images/feed-thumbnails/VPPZ_meBC2-512.jpeg 512w" 
sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/boh_mouse/articles/1e84d170b4212a">【Focal Loss】クラス不均衡に対応する効果的な損失関数</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">はじめにFocal Loss[1]とは、2017年にFacebook AI Research (FAIR) によって提案された損失関数で ICCV 2017 に採択されています。主に物体検出タスクにおけるクラス不均衡問題を解決するために設計されました。本記事では、なぜFocal Lossが必要とされたのか、その理論的背景と導出、そして実際の応用について解説します。 なぜFocal Lossを調べたかSAM（Segment Anything Model）論文を読んでいる際に、SAMの損失関数がFocal LossとDice Lossの組み合わせであることを知りました[2]L...</div><div class="ui-feed-item__date" title="2025-03-04 19:42:54">6日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/m_nakano_teppei/articles/c9362e64f64fa7"><picture><source type="image/avif" 
srcset="../../images/feed-thumbnails/YVrQvddoWB-256.avif 256w, ../../images/feed-thumbnails/YVrQvddoWB-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/YVrQvddoWB-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/YVrQvddoWB-256.jpeg 256w, ../../images/feed-thumbnails/YVrQvddoWB-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/m_nakano_teppei/articles/c9362e64f64fa7">深層学習のパラメーターに関する一般的な値や初期設定について</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">
1. 学習率 (Learning Rate, (&#92;eta))一般的な範囲: (10^{-3}) ～ (10^{-5})初期値の例: 0.001 (Adam, RMSprop) or 0.01 (SGD)調整方法: 学習が進まない場合は増やし、発散する場合は減らす。学習率スケジューリング（Cosine Annealing, Step Decay など）も有効。 2. バッチサイズ (Batch Size)一般的な範囲: 16 ～ 512推奨値:小さい場合 (16, 32): メモリ消費が少なく、勾配のノイズが増えて正則化効果あり大きい場合 ...</div><div class="ui-feed-item__date" title="2025-03-04 06:57:39">6日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/yorozuya/articles/1d373e6b17798f"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/tZaiGir3ER-256.avif 256w, ../../images/feed-thumbnails/tZaiGir3ER-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/tZaiGir3ER-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/tZaiGir3ER-256.jpeg 256w, ../../images/feed-thumbnails/tZaiGir3ER-512.jpeg 512w" 
sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/yorozuya/articles/1d373e6b17798f">Ubuntuサーバの構築 + Dockerを用いたGPU開発環境の構築【2023年12月 / 2024年1月 追記】</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">はじめに本記事はQiitaから移行した記事となります．https://qiita.com/Yorozuya59/items/b4cee5dfdf4d56bfbb2a知り合いとの雑談の中でQiitaとZennのどちらが良いのかという話題になり，どちらにも投稿すれば良いのでは？となったので，コピペと若干の修正を行なったものになります．よろしければ見てやってください．ここ最近，研究室内のサーバを構築する機会が多く，毎回のように検索をしているので，いい加減にまとめておこうと考えた次第です．（近々，もう何台か組み立てる予定もあるので……）研究室に入って2年目の学部生がメモとして書い...</div><div class="ui-feed-item__date" title="2025-03-04 03:20:49">6日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/programing_gym/articles/1ffe7b95cb8506"><picture><source type="image/avif" 
srcset="../../images/feed-thumbnails/YE6gkvXypy-256.avif 256w, ../../images/feed-thumbnails/YE6gkvXypy-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/YE6gkvXypy-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/YE6gkvXypy-256.jpeg 256w, ../../images/feed-thumbnails/YE6gkvXypy-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/programing_gym/articles/1ffe7b95cb8506">Word2VecにおけるN-gramとは？</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">
Word2Vecは、自然言語処理（NLP）で単語の意味をベクトル表現に変換するための手法です。その際、N-gramという概念が関連することがあります。本記事では、Word2VecにおけるN-gramの役割とその応用について詳しく解説します。 1. N-gramとは？N-gram（エヌグラム）とは、連続したN個の単語や文字のシーケンスを指します。一般的に、言語モデルやテキスト解析で使用され、以下のように分類されます。Unigram（1-gram）: 単語単体（例：「AI」）Bigram（2-gram）: 連続する2単語（例：「人工 知能」）Trigram（3-gram...</div><div class="ui-feed-item__date" title="2025-03-03 07:34:47">7日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/nakano_teppei/articles/1bbf82dfd28fd5"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/q8p4bfsDq5-256.avif 256w, ../../images/feed-thumbnails/q8p4bfsDq5-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/q8p4bfsDq5-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/q8p4bfsDq5-256.jpeg 256w, ../../images/feed-thumbnails/q8p4bfsDq5-512.jpeg 512w" 
sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/nakano_teppei/articles/1bbf82dfd28fd5">深層学習における勾配と重みの違いと最先端のアルゴリズム</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">1. はじめに深層学習において「勾配（Gradient）」と「重み（Weight）」は、学習プロセスの中核をなす重要な概念です。本記事では、それぞれの違いを明確にし、さらに最先端の最適化アルゴリズムの紹介と実装例を提供します。 2. 重み（Weight）とは？ 2.1 定義重みとは、ニューラルネットワークの各層において学習されるパラメータであり、入力データの変換を担うものです。学習の過程で更新され、最適な値に収束することで、より正確な予測を可能にします。 2.2 数学的表現与えられたニューラルネットワークの出力が以下のように表されるとします：[y = W x ...</div><div class="ui-feed-item__date" title="2025-03-03 07:09:43">7日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/samemaru07/articles/20a67dfcda67c8"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div 
class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/samemaru07/articles/20a67dfcda67c8">[入門・CNN]画像から背景を削除するAIを作る方法(単語, 理論をおさらい)</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">まずはじめに －自己紹介と本記事についてー初めまして、これが初投稿となります。地方の高専・(当時2年)電子情報工学科に通う「さめまる」と申します。ネットワーク, セキュリティ, Webについて勉強中の身です。本記事は、「CNN(畳み込みニューラルネットワーク)」の基礎, 用語, 理論等を学びたい方向けの記事となります。高専の授業で、&quot;AI演習&quot;というものがあり、自分で「自作画像切り抜きAIを搭載したWebアプリ」を作ることに挑戦しました。個人的には良い精度のものが作れたと思います。当方も学び始めた身で、この分野の知識を定着させたいと思い今回の記事を書きました。一番最後に、Gi...</div><div class="ui-feed-item__date" title="2025-03-02 10:43:12">8日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/giba/articles/learning_method_tips_by_deepresearch"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" 
href="https://zenn.dev/giba/articles/learning_method_tips_by_deepresearch">[DeepResearch]学習を成功させるためのTipsを網羅的に纏めた</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">学習データの準備（データ収集、前処理、アノテーション、データ拡張など）モデルの設計（アーキテクチャの選定、転移学習、自己教師あり学習など）ハイパーパラメータチューニング（学習率の最適化、バッチサイズの選択、正則化技術など）計算リソースの最適化（GPU/TPUの効率的な使用、分散学習、量子化・プルーニングなど）これらのポイントを中心に、最新の論文やベストプラクティスを含めた詳細なTipsをDeepResearchに調査していただいた。 画像認識における深層学習の高度な学習手法（中級者・上級者向け） 1. 学習データの準備 データ収集とラベル付けのベストプラク...</div><div class="ui-feed-item__date" title="2025-03-02 08:37:38">8日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/saitomai/articles/da2930dd7c3d8b"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/saitomai/articles/da2930dd7c3d8b">身体性と世界モデルを統合する知性観の変容：Transformer が問いかける人間理解の境界</a><div 
class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">はじめに Transformerの圧倒的な汎用性 AGIへの道筋2024年12月21日、OpenAIは最先端モデル「o3」を発表した。o3モデルは、プログラミングのベンチマークテストで高得点を記録し、汎用人工知能（AGI）の進捗を測るベンチマークテスト「ARC-AGI」で、人間を超えるスコアを達成した。「ARC-AGI」はIが単にデータの相関関係を学習するのではなく、真に人間のように抽象的な概念を理解し、未知の状況にも対応できる能力を評価するためのテストである。人間には簡単な問題ができていないなど、課題はいるもののこの結果はTransfomerベースのが人間の記号的「...</div><div class="ui-feed-item__date" title="2025-02-26 16:42:38">12日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/rintaro121/articles/bst-pytorch-20250224"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/rintaro121/articles/bst-pytorch-20250224">Alibabaの推薦システムBehavior Sequence Transformer</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">
はじめにこの記事では、Alibabaが提案した「Behavior Sequence Transformer (BST)」というモデルについて解説し、その実装をMovieLensデータセットに適用した例を紹介します。以下は実装です。Repository：https://github.com/rintaro121/behavior-sequence-transformer-pytorchGoogle colab：https://colab.research.google.com/drive/1gv3jAHTLgVChAlw7JyRFM5YTGrCX1PIF?usp=shari...</div><div class="ui-feed-item__date" title="2025-02-24 04:39:41">14日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/giba/articles/neurips2024-detection"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/giba/articles/neurips2024-detection">[NeurIPS2024]気になった物体検出分野の研究まとめ</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">
NeurIPS2024の発表の中で気になった物体検出分野の研究をピックアップ。勉強がてらそれぞれの研究の概要を以下に纏めた。 Adaptive Important Region Selection with Reinforced Hierarchical Search for Dense Object Detectiondense object detectionは様々なドメインに適用されている一方で非常に難しいタスクである。アンカーベースの1ステージ型物体検出器は，複雑かつノイズの多い背景を持つ場合に，多様なタイプの候補アンカーを捉えられず，多くの偽陽性アンカーが生じてしまう...</div><div class="ui-feed-item__date" title="2025-02-22 00:51:09">17日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/mkj/articles/10dfe35cd32026"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/mkj/articles/10dfe35cd32026">強化学習「GRPO」をCartPoleタスクで実装しながら解説</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">
DeepSeek-R1 で有名になった「GRPO」を CartPoleタスクに対して実装しながら解説します（Google Colab上にて）。Pendulum タスク版の実装も用意しています。強化学習手法「GRPO（Group Relative Policy Optimization）」を実装面から理解したい方におすすめの内容です。実装には PyTorchを使用しています。計算実行時間はGoogle Colabの CPU環境で約7分です。今回はGPUは使用していません。（執筆：小川 雄太郎）。!本記事の読者想定DeepSeek-R1で有名になった強化学習手法GRPOを実...</div><div class="ui-feed-item__date" title="2025-02-19 02:50:01">20日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/zenkigen_tech/articles/8356bed81aec91"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/zenkigen_tech/articles/8356bed81aec91">全ての学習率スケジューリングを過去にするRAdamScheduleFreeはGNNsでも健在</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">
はじめにこんにちは。ZENKIGENデータサイエンスチーム所属のredteaです。原籍はオムロンソーシアルソリューションズ株式会社 技術創造センタですが、社外出向でZENKIGENに所属しており、数理最適化や機械学習を用いたデータの分析業務、それらの結果に基づいた顧客への提案をしております[1]。所属チームでXを運用しており、AIに関する情報を発信していますのでご興味あれば覗いてみてください。 本記事の取り組み先日（2024年末）とても便利そうな optimizer RAdamScheduleFree が公開されました。この optimizer は名前の通り、warmup を...</div><div class="ui-feed-item__date" title="2025-02-17 01:30:01">22日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/airiswim/articles/60a6a7638a5ca6"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/airiswim/articles/60a6a7638a5ca6">機械学習のｷをまとめる①最初の一歩🐈</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">
機械学習と深層学習を学び始めた最初の一歩ということで題名の通り書いていきたいと思う。この記事書くきっかけとしては、自分がAIについて勉強しようとした時に何から学び始めればいいのかわからなかったんだ!!!!!!そもそも機械学習と深層学習とか何が違うん？とか、transferってなんやねん？とか論文読んでも...何言ってるかわからん。の状態だった。わたしみたいな初心者の初心者でもわかりやすいように、自分のアウトプットも兼ねて概要からわかりやすく書いていきたいと思います。(もし間違えてる！と思うことがあれば教えてください) 📍1.[概要]機械学習とは？機械学習(ML...</div><div class="ui-feed-item__date" title="2025-02-16 01:44:03">23日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/doctorin/articles/8571c9216589e4"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/doctorin/articles/8571c9216589e4">【Awesome】2025年 デジタル病理学のための深層学習手法まとめ</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">
はじめに空間オミクスやデジタル病理学の分野では、最新のベンチマーク、ワークフロー、基盤モデル、CLIP技術、さらにはオプショナルツールが次々と登場しています。本記事は、筆者がこれまで見てきたデジタル病理画像解析に関するプロジェクトの中でもとくに競争力が高い、または画期的だと思った研究に絞ってまとめました。各リンクから詳細な情報にアクセスできるので、ぜひ参考にしてください。 Benchmarks / Datasetsfor foundation models→ NeurIPS Spotlight 2024for non-foundation models→...</div><div class="ui-feed-item__date" title="2025-02-15 17:57:14">23日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/shogoromaru/articles/ddb9a2ad46dd0c"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/shogoromaru/articles/ddb9a2ad46dd0c">【言語モデルをファインチューニング】感情分析モデルを利用してAmazonレビューの星の数を予想してみた</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">
chatGPTの登場以降、LLMの利用した文章生成は爆発的に広がり、日々の生活に無くてはならなくなったという人も多いのではないでしょうか。今回は、言語モデルの能力を活かして、文章から新たな情報を引き出す研究を学び、実際のデータセットで試してみました。https://github.com/shogoromal/AmazonRating_T5/tree/master 参考にした論文についてhttps://arxiv.org/abs/2302.08624上記の論文を参考にしました。まずはこちらの論文について簡単に解説します。 文章による感情分析この論文で行われているタスクは、...</div><div class="ui-feed-item__date" title="2025-02-11 00:04:29">1ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/channnnsm/articles/51dee09afd983f"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/channnnsm/articles/51dee09afd983f">padding(パディング)とミニバッチ構築はデータ準備の必須テク</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">
はじめにモデルの学習を効率的に進めるために必要な、「パディング」 と 「ミニバッチ構築」 。読み飛ばし気味だったため、一度立ち止まってメモを残します。 padding(パディング)とは？ パディングが必要な理由機械学習モデル、特にディープラーニングモデルは、基本的に同じ形のデータがズラッと並んだものを入力として受け取ります。例えるなら、工場で大量生産するために、ベルトコンベアに乗せる部品の形が全て同じである必要があるようなイメージです。しかし、私たちが扱うデータは、必ずしもいつも同じ形をしているとは限りません。自然言語処理（NLP）: 文章の長さはバラバラですよ...</div><div class="ui-feed-item__date" title="2025-02-10 01:11:39">1ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/starai/articles/3e8075d1b5c142"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/starai/articles/3e8075d1b5c142">文献調査: 「TAID: Temporally Adaptive Interpolated Distillation」</a><div class="ui-feed-item__blog-title">Zennの「ディープラーニング」のフィード</div><div class="ui-feed-item__summary">
1. はじめにお疲れ様です！社員の中岸が投稿します！今回は、知識蒸留によるモデル圧縮について興味深い議論がされている Sakana AIの文献（タイトルに全部入らなかった… ）を調査してみたのでその内容を自分なりにまとめてみました！（なお、「➡」に続いている文章は、読んでいる際に自分が感じたことであり、論文の内容ではないのでご注意下さい。また、誤字や間違って理解しているところも多々あるかもしれませんがご了承ください。）今回の記事は、下記文献(URL)の内容を自分が読んでまとめた結果になります。また、図や表などはこの文献やプロジェクトブログなどから引用しています(Blog, Gi...</div><div class="ui-feed-item__date" title="2025-02-04 18:02:25">1ヶ月前</div></div></div></div></div></section></main><footer role="contentinfo" class="ui-section-footer"><div class="ui-layout-container"><div class="ui-layout-column-6 ui-layout-column-center"><div class="ui-component-cta ui-layout-flex ui-section-footer__site-info"><p class="ui-text-note">このサイトは<br>記事を読んでその企業の技術・カルチャーを知れることや<br>質の高い技術情報を得られることを目的としています。</p><p class="ui-text-note">追加したいブログがある場合は<br><a href="https://github.com/univac-1/ai-info-rss-feed#%E3%82%B5%E3%82%A4%E3%83%88%E3%81%AE%E8%BF%BD%E5%8A%A0%E6%96%B9%E6%B3%95" target="_blank">サイトの追加方法</a> をご参照ください。</p></div></div></div><div class="ui-layout-container"><div 
class="ui-section-footer__layout ui-layout-flex"><p class="ui-section-footer--copyright ui-text-note"><a class="ui-text-note" href="https://github.com/univac-1/" target="_blank"><small>@univac-1</small></a></p><a href="https://github.com/univac-1/ai-info-rss-feed/" role="link" aria-label="#" class="ui-text-note" target="_blank"><small>GitHub</small></a></div></div></footer></body></html>